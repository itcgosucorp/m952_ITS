{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74882fd",
   "metadata": {},
   "source": [
    "**<h3 style=\"text-align: center; color: #edc9af;\">CONVERT AND MERGE FILES TO ONE FILE </h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129af48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cc7bba",
   "metadata": {},
   "source": [
    "#### **Event login**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ab4b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_file=\"login\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d772b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"data/data_json\"\n",
    "output_folder = \"data\"\n",
    "\n",
    "jsonl_files = sorted([\n",
    "    f for f in os.listdir(input_folder)\n",
    "    if f.startswith(f\"tmp_{event_file}\") and f.endswith(\".jsonl\")\n",
    "])\n",
    "\n",
    "if not jsonl_files:\n",
    "    print(\"Cannot find *.jsonl in data/data_json/\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48f7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_from_filename(filename: str, part: str) -> str:\n",
    "    base = filename.replace(\".jsonl\", \"\").split(\"tmp_\")[1]\n",
    "    start_str, end_str = base.split(\"_to_\")\n",
    "    return start_str if part == 'start' else end_str\n",
    "\n",
    "def format_for_filename(ts: str) -> str:\n",
    "    return ts.replace(\":\", \"-\").replace(\"T\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686fb6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_raw = extract_datetime_from_filename(jsonl_files[0], 'start')\n",
    "last_time_raw  = extract_datetime_from_filename(jsonl_files[-1], 'end')\n",
    "\n",
    "first_time = format_for_filename(first_time_raw)\n",
    "last_time  = format_for_filename(last_time_raw)\n",
    "\n",
    "output_csv_name = f\"m952_{first_time}_to_{last_time}.csv\"\n",
    "output_csv_path = os.path.join(output_folder, output_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f32ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: tmp_login_2025-05-04_00-00-00_to_2025-05-05_00-00-00.jsonl — 475205 records\n",
      "Done: tmp_login_2025-05-05_00-00-00_to_2025-05-06_00-00-00.jsonl — 589090 records\n",
      "Done: tmp_login_2025-05-06_00-00-00_to_2025-05-07_00-00-00.jsonl — 554523 records\n",
      "Done: tmp_login_2025-05-07_00-00-00_to_2025-05-08_00-00-00.jsonl — 596651 records\n",
      "Done: tmp_login_2025-05-08_00-00-00_to_2025-05-09_00-00-00.jsonl — 562847 records\n",
      "Done: tmp_login_2025-05-09_00-00-00_to_2025-05-10_00-00-00.jsonl — 588048 records\n",
      "Done: tmp_login_2025-05-10_00-00-00_to_2025-05-11_00-00-00.jsonl — 562190 records\n",
      "Done: tmp_login_2025-05-11_00-00-00_to_2025-05-12_00-00-00.jsonl — 557629 records\n",
      "Done: tmp_login_2025-05-12_00-00-00_to_2025-05-13_00-00-00.jsonl — 574555 records\n",
      "Done: tmp_login_2025-05-13_00-00-00_to_2025-05-14_00-00-00.jsonl — 551753 records\n",
      "Done: tmp_login_2025-05-14_00-00-00_to_2025-05-15_00-00-00.jsonl — 585040 records\n",
      "Done: tmp_login_2025-05-15_00-00-00_to_2025-05-16_00-00-00.jsonl — 379240 records\n",
      "Done: tmp_login_2025-05-16_00-00-00_to_2025-05-17_00-00-00.jsonl — 376384 records\n",
      "Done: tmp_login_2025-05-17_00-00-00_to_2025-05-18_00-00-00.jsonl — 334579 records\n",
      "Done: tmp_login_2025-05-18_00-00-00_to_2025-05-19_00-00-00.jsonl — 352381 records\n",
      "Done: tmp_login_2025-05-19_00-00-00_to_2025-05-20_00-00-00.jsonl — 409100 records\n",
      "Done: tmp_login_2025-05-20_00-00-00_to_2025-05-21_00-00-00.jsonl — 367447 records\n",
      "Done: tmp_login_2025-05-21_00-00-00_to_2025-05-22_00-00-00.jsonl — 409326 records\n",
      "Done: tmp_login_2025-05-22_00-00-00_to_2025-05-23_00-00-00.jsonl — 355642 records\n",
      "Done: tmp_login_2025-05-23_00-00-00_to_2025-05-24_00-00-00.jsonl — 419295 records\n",
      "Done: tmp_login_2025-05-24_00-00-00_to_2025-05-25_00-00-00.jsonl — 338452 records\n",
      "Done: tmp_login_2025-05-25_00-00-00_to_2025-05-26_00-00-00.jsonl — 336948 records\n",
      "Done: tmp_login_2025-05-26_00-00-00_to_2025-05-27_00-00-00.jsonl — 409581 records\n",
      "Done: tmp_login_2025-05-27_00-00-00_to_2025-05-28_00-00-00.jsonl — 346117 records\n",
      "Done: tmp_login_2025-05-28_00-00-00_to_2025-05-29_00-00-00.jsonl — 414296 records\n",
      "Done: tmp_login_2025-05-29_00-00-00_to_2025-05-30_00-00-00.jsonl — 361642 records\n",
      "Done: tmp_login_2025-05-30_00-00-00_to_2025-05-31_00-00-00.jsonl — 389731 records\n",
      "Done: tmp_login_2025-05-31_00-00-00_to_2025-06-01_00-00-00.jsonl — 330881 records\n",
      "Done: tmp_login_2025-06-01_00-00-00_to_2025-06-02_00-00-00.jsonl — 358868 records\n",
      "Done: tmp_login_2025-06-02_00-00-00_to_2025-06-03_00-00-00.jsonl — 413799 records\n",
      "Done: tmp_login_2025-06-03_00-00-00_to_2025-06-04_00-00-00.jsonl — 380775 records\n",
      "Done: tmp_login_2025-06-04_00-00-00_to_2025-06-05_00-00-00.jsonl — 392934 records\n",
      "Done: tmp_login_2025-06-05_00-00-00_to_2025-06-06_00-00-00.jsonl — 339876 records\n",
      "Done: tmp_login_2025-06-06_00-00-00_to_2025-06-07_00-00-00.jsonl — 413240 records\n",
      "Done: tmp_login_2025-06-07_00-00-00_to_2025-06-08_00-00-00.jsonl — 343095 records\n",
      "Done: tmp_login_2025-06-08_00-00-00_to_2025-06-09_00-00-00.jsonl — 336841 records\n",
      "Done: tmp_login_2025-06-09_00-00-00_to_2025-06-10_00-00-00.jsonl — 391060 records\n",
      "Done: tmp_login_2025-06-10_00-00-00_to_2025-06-11_00-00-00.jsonl — 333974 records\n",
      "Done: tmp_login_2025-06-11_00-00-00_to_2025-06-12_00-00-00.jsonl — 315480 records\n",
      "Done: tmp_login_2025-06-12_00-00-00_to_2025-06-13_00-00-00.jsonl — 284571 records\n",
      "Done: tmp_login_2025-06-13_00-00-00_to_2025-06-14_00-00-00.jsonl — 327648 records\n",
      "Done: tmp_login_2025-06-14_00-00-00_to_2025-06-15_00-00-00.jsonl — 261823 records\n",
      "Done: tmp_login_2025-06-15_00-00-00_to_2025-06-16_00-00-00.jsonl — 267164 records\n",
      "Done: tmp_login_2025-06-16_00-00-00_to_2025-06-17_00-00-00.jsonl — 359854 records\n",
      "Done: tmp_login_2025-06-17_00-00-00_to_2025-06-18_00-00-00.jsonl — 356828 records\n",
      "Done: tmp_login_2025-06-18_00-00-00_to_2025-06-19_00-00-00.jsonl — 440996 records\n",
      "\n",
      "Completed convert 18,847,399 records to: data\\m952_login_2025-05-04_00-00-00_to_2025-06-19_00-00-00.csv\n"
     ]
    }
   ],
   "source": [
    "columns_keep = [\n",
    "    \"@timestamp\",\n",
    "    \"user.id\",\n",
    "    \"event.its.properties.gold\",\n",
    "    \"event.its.properties.diamond\",\n",
    "    \"event.its.properties.power_point\",\n",
    "    \"event.its.properties.level\",\n",
    "    \"event.its.properties.vip_level\",\n",
    "    \"event.its.properties.dragon_gold\"\n",
    "]\n",
    "\n",
    "if os.path.exists(output_csv_path):\n",
    "    print(f\"File exists: {output_csv_path} , stopped.\")\n",
    "\n",
    "else:\n",
    "    is_first = True\n",
    "    total_records = 0\n",
    "\n",
    "    for file in jsonl_files:\n",
    "        full_path = os.path.join(input_folder, file)\n",
    "        with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = []\n",
    "            for line in f:\n",
    "                try:\n",
    "                    obj = json.loads(line.strip())\n",
    "                    lines.append(obj)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding line in file: {file}\")\n",
    "\n",
    "            if lines:\n",
    "                df = pd.json_normalize(lines)\n",
    "\n",
    "                for col in columns_keep:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = None\n",
    "\n",
    "                df = df[columns_keep]\n",
    "                df.to_csv(output_csv_path, index=False, mode='w' if is_first else 'a', header=is_first)\n",
    "                total_records += len(df)\n",
    "                is_first = False\n",
    "                print(f\"Done: {file} — {len(df)} records\")\n",
    "\n",
    "    print(f\"\\nCompleted convert {total_records:,} records to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdfda2",
   "metadata": {},
   "source": [
    "#### **Not event login**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1cc080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_file=\"shopflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52599f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_keep = [\n",
    "#     \"@timestamp\", \"user.id\",\n",
    "#     'event.its.properties.product_name',\n",
    "#     'event.its.properties.payment_amount',\n",
    "# ]\n",
    "columns_keep = [\n",
    "    '@timestamp',\n",
    "    'user.id',\n",
    "    'event.its.properties.i_money_type',\n",
    "    'event.its.properties.i_zone_area_id',\n",
    "    'event.its.properties.quantity',\n",
    "    'event.its.properties.i_money_value',\n",
    "    'event.its.properties.power_point',\n",
    "    'event.its.properties.i_shop_type',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_jsonl_to_csv(\n",
    "    jsonl_files,\n",
    "    input_folder,\n",
    "    output_csv_path,\n",
    "    columns_keep\n",
    "):\n",
    "    is_first = True\n",
    "    total_records = 0\n",
    "\n",
    "    for file in jsonl_files:\n",
    "        full_path = os.path.join(input_folder, file)\n",
    "        with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = []\n",
    "            for line in f:\n",
    "                try:\n",
    "                    obj = json.loads(line.strip())\n",
    "                    lines.append(obj)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding line in file: {file}\")\n",
    "\n",
    "        if lines:  \n",
    "            df = pd.json_normalize(lines)\n",
    "            for col in columns_keep:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = None\n",
    "\n",
    "            df = df[columns_keep]\n",
    "\n",
    "            df.to_csv(output_csv_path, index=False, mode='w' if is_first else 'a', header=is_first)\n",
    "            total_records += len(df)\n",
    "            is_first = False\n",
    "\n",
    "            print(f\"Done: {file} ({len(df)} records)\")\n",
    "\n",
    "    print(f\"\\nConverted {total_records:,} records to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fbdfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"data/data_json\"\n",
    "jsonl_files = sorted([\n",
    "    f for f in os.listdir(input_folder)\n",
    "    if f.startswith(f\"tmp_{event_file}\") and f.endswith(\".jsonl\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6191a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: tmp_shopflow_2025-05-04_00-00-00_to_2025-05-05_00-00-00.jsonl (2414669 records)\n",
      "Done: tmp_shopflow_2025-05-05_00-00-00_to_2025-05-06_00-00-00.jsonl (2066940 records)\n",
      "Done: tmp_shopflow_2025-05-06_00-00-00_to_2025-05-07_00-00-00.jsonl (1895001 records)\n",
      "Done: tmp_shopflow_2025-05-07_00-00-00_to_2025-05-08_00-00-00.jsonl (1951789 records)\n",
      "Done: tmp_shopflow_2025-05-08_00-00-00_to_2025-05-09_00-00-00.jsonl (1939449 records)\n",
      "Done: tmp_shopflow_2025-05-09_00-00-00_to_2025-05-10_00-00-00.jsonl (1903325 records)\n",
      "Done: tmp_shopflow_2025-05-10_00-00-00_to_2025-05-11_00-00-00.jsonl (1916484 records)\n",
      "Done: tmp_shopflow_2025-05-11_00-00-00_to_2025-05-12_00-00-00.jsonl (1874801 records)\n",
      "Done: tmp_shopflow_2025-05-12_00-00-00_to_2025-05-13_00-00-00.jsonl (1847127 records)\n",
      "Done: tmp_shopflow_2025-05-13_00-00-00_to_2025-05-14_00-00-00.jsonl (1542640 records)\n",
      "Done: tmp_shopflow_2025-05-14_00-00-00_to_2025-05-15_00-00-00.jsonl (1796364 records)\n",
      "Done: tmp_shopflow_2025-05-15_00-00-00_to_2025-05-16_00-00-00.jsonl (1798022 records)\n",
      "Done: tmp_shopflow_2025-05-16_00-00-00_to_2025-05-17_00-00-00.jsonl (1750410 records)\n",
      "Done: tmp_shopflow_2025-05-17_00-00-00_to_2025-05-18_00-00-00.jsonl (1756276 records)\n",
      "Done: tmp_shopflow_2025-05-18_00-00-00_to_2025-05-19_00-00-00.jsonl (1727902 records)\n",
      "Done: tmp_shopflow_2025-05-19_00-00-00_to_2025-05-20_00-00-00.jsonl (1639066 records)\n",
      "Done: tmp_shopflow_2025-05-20_00-00-00_to_2025-05-21_00-00-00.jsonl (1931716 records)\n",
      "Done: tmp_shopflow_2025-05-21_00-00-00_to_2025-05-22_00-00-00.jsonl (1970452 records)\n",
      "Done: tmp_shopflow_2025-05-22_00-00-00_to_2025-05-23_00-00-00.jsonl (1936004 records)\n",
      "Done: tmp_shopflow_2025-05-23_00-00-00_to_2025-05-24_00-00-00.jsonl (1857962 records)\n",
      "Done: tmp_shopflow_2025-05-24_00-00-00_to_2025-05-25_00-00-00.jsonl (1595490 records)\n",
      "Done: tmp_shopflow_2025-05-25_00-00-00_to_2025-05-26_00-00-00.jsonl (1849223 records)\n",
      "Done: tmp_shopflow_2025-05-26_00-00-00_to_2025-05-27_00-00-00.jsonl (1963336 records)\n",
      "Done: tmp_shopflow_2025-05-27_00-00-00_to_2025-05-28_00-00-00.jsonl (1880965 records)\n",
      "Done: tmp_shopflow_2025-05-28_00-00-00_to_2025-05-29_00-00-00.jsonl (1822074 records)\n",
      "Done: tmp_shopflow_2025-05-29_00-00-00_to_2025-05-30_00-00-00.jsonl (1852125 records)\n",
      "Done: tmp_shopflow_2025-05-30_00-00-00_to_2025-05-31_00-00-00.jsonl (1592606 records)\n",
      "Done: tmp_shopflow_2025-05-31_00-00-00_to_2025-06-01_00-00-00.jsonl (1868088 records)\n",
      "Done: tmp_shopflow_2025-06-01_00-00-00_to_2025-06-02_00-00-00.jsonl (1785423 records)\n",
      "Done: tmp_shopflow_2025-06-02_00-00-00_to_2025-06-03_00-00-00.jsonl (1891006 records)\n",
      "Done: tmp_shopflow_2025-06-03_00-00-00_to_2025-06-04_00-00-00.jsonl (1861482 records)\n",
      "Done: tmp_shopflow_2025-06-04_00-00-00_to_2025-06-05_00-00-00.jsonl (1629660 records)\n",
      "Done: tmp_shopflow_2025-06-05_00-00-00_to_2025-06-06_00-00-00.jsonl (1849362 records)\n",
      "Done: tmp_shopflow_2025-06-06_00-00-00_to_2025-06-07_00-00-00.jsonl (1767763 records)\n",
      "Done: tmp_shopflow_2025-06-07_00-00-00_to_2025-06-08_00-00-00.jsonl (1767581 records)\n",
      "Done: tmp_shopflow_2025-06-08_00-00-00_to_2025-06-09_00-00-00.jsonl (1766566 records)\n",
      "Done: tmp_shopflow_2025-06-09_00-00-00_to_2025-06-10_00-00-00.jsonl (1837530 records)\n",
      "Done: tmp_shopflow_2025-06-10_00-00-00_to_2025-06-11_00-00-00.jsonl (1718082 records)\n",
      "Done: tmp_shopflow_2025-06-11_00-00-00_to_2025-06-12_00-00-00.jsonl (913662 records)\n",
      "Done: tmp_shopflow_2025-06-12_00-00-00_to_2025-06-13_00-00-00.jsonl (1069454 records)\n",
      "Done: tmp_shopflow_2025-06-13_00-00-00_to_2025-06-14_00-00-00.jsonl (1189299 records)\n",
      "Done: tmp_shopflow_2025-06-14_00-00-00_to_2025-06-15_00-00-00.jsonl (1248025 records)\n",
      "Done: tmp_shopflow_2025-06-15_00-00-00_to_2025-06-16_00-00-00.jsonl (1247139 records)\n",
      "Done: tmp_shopflow_2025-06-16_00-00-00_to_2025-06-17_00-00-00.jsonl (1446911 records)\n",
      "Done: tmp_shopflow_2025-06-17_00-00-00_to_2025-06-18_00-00-00.jsonl (1702220 records)\n",
      "Done: tmp_shopflow_2025-06-18_00-00-00_to_2025-06-19_00-00-00.jsonl (1751183 records)\n",
      "\n",
      "🎉 Converted 80,382,654 records to: data/m952_shopflow_2025-05-04_00-00-00_to_2025-06-19_00-00-00.csv\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2025-05-04_00-00-00\"\n",
    "end_date   = \"2025-06-19_00-00-00\"\n",
    "output_csv_path = f\"data/m952_{event_file}_{start_date}_to_{end_date}.csv\"\n",
    "convert_jsonl_to_csv(\n",
    "    jsonl_files=jsonl_files,\n",
    "    input_folder=input_folder,\n",
    "    output_csv_path=output_csv_path,\n",
    "    columns_keep=columns_keep\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
