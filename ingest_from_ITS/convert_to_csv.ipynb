{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74882fd",
   "metadata": {},
   "source": [
    "**<h3 style=\"text-align: center; color: #edc9af;\">CONVERT AND MERGE FILES TO ONE FILE </h3>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129af48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab4b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_file=\"equipenhance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d772b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"data/data_json\"\n",
    "output_folder = \"data\"\n",
    "\n",
    "jsonl_files = sorted([\n",
    "    f for f in os.listdir(input_folder)\n",
    "    if f.startswith(f\"tmp_{event_file}\") and f.endswith(\".jsonl\")\n",
    "])\n",
    "\n",
    "if not jsonl_files:\n",
    "   print(\"Cannot find*.jsonl in data/data_json/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f11a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_from_filename(filename: str, part: str) -> str:\n",
    "    base = filename.replace(\".jsonl\", \"\").split(\"tmp_\")[1]\n",
    "    start_str, end_str = base.split(\"_to_\")\n",
    "    return start_str if part == 'start' else end_str\n",
    "\n",
    "first_time_raw = extract_datetime_from_filename(jsonl_files[0], 'start')\n",
    "last_time_raw  = extract_datetime_from_filename(jsonl_files[-1], 'end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b6bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_filename(ts: str) -> str:\n",
    "    return ts.replace(\":\", \"-\").replace(\"T\", \"_\")\n",
    "\n",
    "first_time = format_for_filename(first_time_raw)\n",
    "last_time  = format_for_filename(last_time_raw)\n",
    "\n",
    "output_csv_name = f\"m952_{first_time}_to_{last_time}.csv\"\n",
    "output_csv_path = os.path.join(output_folder, output_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb51f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: tmp_equipenhance_2025-05-15_00-00-00_to_2025-05-16_00-00-00.jsonl — 166238 records\n",
      "Done: tmp_equipenhance_2025-05-16_00-00-00_to_2025-05-17_00-00-00.jsonl — 173005 records\n",
      "Done: tmp_equipenhance_2025-05-17_00-00-00_to_2025-05-18_00-00-00.jsonl — 167147 records\n",
      "Done: tmp_equipenhance_2025-05-18_00-00-00_to_2025-05-19_00-00-00.jsonl — 148782 records\n",
      "Done: tmp_equipenhance_2025-05-19_00-00-00_to_2025-05-20_00-00-00.jsonl — 195425 records\n",
      "Done: tmp_equipenhance_2025-05-20_00-00-00_to_2025-05-21_00-00-00.jsonl — 180148 records\n",
      "Done: tmp_equipenhance_2025-05-21_00-00-00_to_2025-05-22_00-00-00.jsonl — 172785 records\n",
      "Done: tmp_equipenhance_2025-05-22_00-00-00_to_2025-05-23_00-00-00.jsonl — 164246 records\n",
      "Done: tmp_equipenhance_2025-05-23_00-00-00_to_2025-05-24_00-00-00.jsonl — 165160 records\n",
      "Done: tmp_equipenhance_2025-05-24_00-00-00_to_2025-05-25_00-00-00.jsonl — 153422 records\n",
      "Done: tmp_equipenhance_2025-05-25_00-00-00_to_2025-05-26_00-00-00.jsonl — 157622 records\n",
      "Done: tmp_equipenhance_2025-05-26_00-00-00_to_2025-05-27_00-00-00.jsonl — 206626 records\n",
      "Done: tmp_equipenhance_2025-05-27_00-00-00_to_2025-05-28_00-00-00.jsonl — 178350 records\n",
      "Done: tmp_equipenhance_2025-05-28_00-00-00_to_2025-05-29_00-00-00.jsonl — 182992 records\n",
      "Done: tmp_equipenhance_2025-05-29_00-00-00_to_2025-05-30_00-00-00.jsonl — 158465 records\n",
      "Done: tmp_equipenhance_2025-05-30_00-00-00_to_2025-05-31_00-00-00.jsonl — 154404 records\n",
      "Done: tmp_equipenhance_2025-05-31_00-00-00_to_2025-06-01_00-00-00.jsonl — 159997 records\n",
      "Done: tmp_equipenhance_2025-06-01_00-00-00_to_2025-06-02_00-00-00.jsonl — 157760 records\n",
      "Done: tmp_equipenhance_2025-06-02_00-00-00_to_2025-06-03_00-00-00.jsonl — 185089 records\n",
      "Done: tmp_equipenhance_2025-06-03_00-00-00_to_2025-06-04_00-00-00.jsonl — 102238 records\n",
      "Done: tmp_equipenhance_2025-06-04_00-00-00_to_2025-06-05_00-00-00.jsonl — 21582 records\n",
      "Done: tmp_equipenhance_2025-06-05_00-00-00_to_2025-06-06_00-00-00.jsonl — 22316 records\n",
      "Done: tmp_equipenhance_2025-06-06_00-00-00_to_2025-06-07_00-00-00.jsonl — 20359 records\n",
      "Done: tmp_equipenhance_2025-06-07_00-00-00_to_2025-06-08_00-00-00.jsonl — 19085 records\n",
      "Done: tmp_equipenhance_2025-06-08_00-00-00_to_2025-06-09_00-00-00.jsonl — 20890 records\n",
      "Done: tmp_equipenhance_2025-06-09_00-00-00_to_2025-06-10_00-00-00.jsonl — 25487 records\n",
      "Done: tmp_equipenhance_2025-06-10_00-00-00_to_2025-06-11_00-00-00.jsonl — 23419 records\n",
      "Done: tmp_equipenhance_2025-06-11_00-00-00_to_2025-06-12_00-00-00.jsonl — 13074 records\n",
      "Done: tmp_equipenhance_2025-06-12_00-00-00_to_2025-06-13_00-00-00.jsonl — 16847 records\n",
      "Done: tmp_equipenhance_2025-06-13_00-00-00_to_2025-06-14_00-00-00.jsonl — 16635 records\n",
      "Done: tmp_equipenhance_2025-06-14_00-00-00_to_2025-06-15_00-00-00.jsonl — 15966 records\n",
      "Done: tmp_equipenhance_2025-06-15_00-00-00_to_2025-06-16_00-00-00.jsonl — 14518 records\n",
      "\n",
      "Completed convert 3,560,079 records to: data\\m952_equipenhance_2025-05-15_00-00-00_to_2025-06-16_00-00-00.csv\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(output_csv_path):\n",
    "    print(f\"File exist: {output_csv_path} , stopped.\")\n",
    "\n",
    "else: \n",
    "    all_files = sorted(jsonl_files)\n",
    "    is_first = True\n",
    "    total_records = 0\n",
    "\n",
    "    for file in all_files:\n",
    "        full_path = os.path.join(input_folder, file)\n",
    "        with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = []\n",
    "            for line in f:\n",
    "                try:\n",
    "                    obj = json.loads(line.strip())\n",
    "                    lines.append(obj)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding line in file: {file}\")\n",
    "            \n",
    "            if lines:\n",
    "                df = pd.json_normalize(lines)\n",
    "                df.to_csv(output_csv_path, index=False, mode='w' if is_first else 'a', header=is_first)\n",
    "                total_records += len(df)\n",
    "                is_first = False\n",
    "                print(f\"Done: {file} — {len(df)} records\")\n",
    "\n",
    "    print(f\"\\nCompleted convert {total_records:,} records to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32ced4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b7b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb9c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdfda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
